{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement cv2 (from versions: )\n",
      "No matching distribution found for cv2\n"
     ]
    }
   ],
   "source": [
    "!pip install cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Let's load a simple image with 3 black squares\n",
    "image = cv2.imread('C:\\\\Users\\\\Sabakat\\\\Desktop\\\\images\\\\shapes.jpg') \n",
    "cv2.imshow('Input Image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Grayscale\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find Canny edges\n",
    "edged = cv2.Canny(gray, 30, 200)\n",
    "cv2.imshow('Canny Edges', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Finding Contours\n",
    "# Use a copy of your image e.g. edged.copy(), since findContours alters the image\n",
    "contours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "cv2.imshow('Canny Edges After Contouring', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(\"Number of Contours found = \" + str(len(contours)))\n",
    "\n",
    "# Draw all contours\n",
    "# Use '-1' as the 3rd parameter to draw all\n",
    "cv2.drawContours(image, contours, -1, (0,255,0), 3)\n",
    "\n",
    "cv2.imshow('Contours', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Sorting Contours\n",
    "\n",
    "We can sort contours in many ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of contours found =  4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load our image\n",
    "#image = cv2.imread('C:\\\\Users\\\\Sabakat\\\\Desktop\\\\images\\\\essan.jpg')\n",
    "image = cv2.imread('C:\\\\Users\\\\Sabakat\\\\Desktop\\\\images\\\\bunchofshapes.jpg')\n",
    "cv2.imshow('0 - Original Image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Create a black image with same dimensions as our loaded image\n",
    "blank_image = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "\n",
    "# Create a copy of our original image\n",
    "orginal_image = image\n",
    "\n",
    "# Grayscale our image\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find Canny edges\n",
    "edged = cv2.Canny(gray, 50, 200)\n",
    "cv2.imshow('1 - Canny Edges', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Find contours and print how many were found\n",
    "contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "print (\"Number of contours found = \", len(contours))\n",
    "\n",
    "#Draw all contours\n",
    "cv2.drawContours(blank_image, contours, -1, (0,255,0), 3)\n",
    "cv2.imshow('2 - All Contours over blank image', blank_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Draw all contours over blank image\n",
    "cv2.drawContours(image, contours, -1, (0,255,0), 3)\n",
    "cv2.imshow('3 - All Contours', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now sort by area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contor Areas before sorting\n",
      "[20587.5, 22901.5, 66579.5, 90222.0]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function we'll use to display contour area\n",
    "\n",
    "def get_contour_areas(contours):\n",
    "    # returns the areas of all contours as list\n",
    "    all_areas = []\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        all_areas.append(area)\n",
    "    return all_areas\n",
    "\n",
    "# Load our image\n",
    "image = cv2.imread('C:\\\\Users\\\\Sabakat\\\\Desktop\\\\images\\\\bunchofshapes.jpg')\n",
    "orginal_image = image\n",
    "\n",
    "# Let's print the areas of the contours before sorting\n",
    "print (\"Contor Areas before sorting\")\n",
    "print (get_contour_areas(contours))\n",
    "\n",
    "# Sort contours large to small\n",
    "sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "#sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)[:3]\n",
    "\n",
    "#print (\"Contor Areas after sorting\")\n",
    "#print get_contour_areas(sorted_contours)\n",
    "\n",
    "# Iterate over our contours and draw one at a time\n",
    "for c in sorted_contours:\n",
    "    cv2.drawContours(orginal_image, [c], -1, (255,0,0), 3)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.imshow('Contours by area', orginal_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_shape_number_1.jpg\n",
      "output_shape_number_2.jpg\n",
      "output_shape_number_3.jpg\n",
      "output_shape_number_4.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Functions we'll use for sorting by position\n",
    "\n",
    "def x_cord_contour(contours):\n",
    "    #Returns the X cordinate for the contour centroid\n",
    "    if cv2.contourArea(contours) > 10:\n",
    "        M = cv2.moments(contours)\n",
    "        return (int(M['m10']/M['m00']))\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "def label_contour_center(image, c):\n",
    "    # Places a red circle on the centers of contours\n",
    "    M = cv2.moments(c)\n",
    "    cx = int(M['m10'] / M['m00'])\n",
    "    cy = int(M['m01'] / M['m00'])\n",
    " \n",
    "    # Draw the countour number on the image\n",
    "    cv2.circle(image,(cx,cy), 10, (0,0,255), -1)\n",
    "    return image\n",
    "\n",
    "\n",
    "# Load our image\n",
    "image = cv2.imread('images/bunchofshapes.jpg')\n",
    "orginal_image = image.copy()\n",
    "\n",
    "\n",
    "# Computer Center of Mass or centroids and draw them on our image\n",
    "for (i, c) in enumerate(contours):\n",
    "    orig = label_contour_center(image, c)\n",
    " \n",
    "cv2.imshow(\"4 - Contour Centers \", image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Sort by left to right using our x_cord_contour function\n",
    "contours_left_to_right = sorted(contours, key = x_cord_contour, reverse = False)\n",
    "\n",
    "\n",
    "# Labeling Contours left to right\n",
    "for (i,c)  in enumerate(contours_left_to_right):\n",
    "    cv2.drawContours(orginal_image, [c], -1, (0,0,255), 3)  \n",
    "    M = cv2.moments(c)\n",
    "    cx = int(M['m10'] / M['m00'])\n",
    "    cy = int(M['m01'] / M['m00'])\n",
    "    cv2.putText(orginal_image, str(i+1), (cx, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow('6 - Left to Right Contour', orginal_image)\n",
    "    cv2.waitKey(0)\n",
    "    (x, y, w, h) = cv2.boundingRect(c)  \n",
    "    \n",
    "    # Let's now crop each contour and save these images\n",
    "    cropped_contour = orginal_image[y:y + h, x:x + w]\n",
    "    image_name = \"output_shape_number_\" + str(i+1) + \".jpg\"\n",
    "    print (image_name)\n",
    "    cv2.imwrite(image_name, cropped_contour)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Approximating Contours and Convex Hull \n",
    "\n",
    "***cv2.approxPolyDP(contour, Approximation Accuracy, Closed)***\n",
    "- **contour** ‚Äì is the individual contour we wish to approximate\n",
    "- **Approximation Accuracy** ‚Äì Important parameter is determining the accuracy of the approximation. Small values give precise-  approximations, large values give more generic approximation. A good rule of thumb is less than 5% of the contour perimeter\n",
    "- **Closed** ‚Äì a Boolean value that states whether the approximate contour should be open or closed \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load image and keep a copy\n",
    "image = cv2.imread('images/house.jpg')\n",
    "orig_image = image.copy()\n",
    "cv2.imshow('Original Image', orig_image)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Grayscale and binarize\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Find contours \n",
    "contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# Iterate through each contour and compute the bounding rectangle\n",
    "for c in contours:\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    cv2.rectangle(orig_image,(x,y),(x+w,y+h),(0,0,255),2)    \n",
    "    cv2.imshow('Bounding Rectangle', orig_image)\n",
    "\n",
    "cv2.waitKey(0) \n",
    "    \n",
    "# Iterate through each contour and compute the approx contour\n",
    "for c in contours:\n",
    "    # Calculate accuracy as a percent of the contour perimeter\n",
    "    accuracy = 0.03 * cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, accuracy, True)\n",
    "    cv2.drawContours(image, [approx], 0, (0, 255, 0), 2)\n",
    "    cv2.imshow('Approx Poly DP', image)\n",
    "    \n",
    "cv2.waitKey(0)   \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convex Hull\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('images/hand.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Threshold the image\n",
    "ret, thresh = cv2.threshold(gray, 176, 255, 0)\n",
    "\n",
    "# Find contours \n",
    "contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "# Sort Contors by area and then remove the largest frame contour\n",
    "n = len(contours) - 1\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=False)[:n]\n",
    "\n",
    "# Iterate through contours and draw the convex hull\n",
    "for c in contours:\n",
    "    hull = cv2.convexHull(c)\n",
    "    cv2.drawContours(image, [hull], 0, (0, 255, 0), 2)\n",
    "    cv2.imshow('Convex Hull', image)\n",
    "\n",
    "cv2.waitKey(0)    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Shape Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cv2.matchShapes(contour template, contour, method, method parameter)**\n",
    "\n",
    "**Output** ‚Äì match value (lower values means a closer match)\n",
    "\n",
    "- Contour Template ‚Äì This is our reference contour that we‚Äôre trying to find in the new image\n",
    "- Contour ‚Äì The individual contour we are checking against\n",
    "- Method ‚Äì Type of contour matching (1, 2, 3)\n",
    "- Method Parameter ‚Äì leave alone as 0.0 (not fully utilized in python OpenCV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13081816783853514\n",
      "0.1590200533978871\n",
      "0.1498791568252558\n",
      "0.07094034474475601\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the shape template or reference image\n",
    "template = cv2.imread('C:\\\\Users\\\\Sabakat\\\\Desktop\\\\images\\\\4star.jpg',0)\n",
    "cv2.imshow('Template', template)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Load the target image with the shapes we're trying to match\n",
    "target_gray = cv2.cvtColor(target,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold both images first before using cv2.findContours\n",
    "ret, thresh1 = cv2.threshold(template, 127, 255, 0)\n",
    "ret, thresh2 = cv2.threshold(target_gray, 127, 255, 0)\n",
    "\n",
    "# Find contours in template\n",
    "contours, hierarchy = cv2.findContours(thresh1, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# We need to sort the contours by area so that we can remove the largest\n",
    "# contour which is the image outline\n",
    "sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "# We extract the second largest contour which will be our template contour\n",
    "template_contour = contours[1]\n",
    "\n",
    "# Extract contours from second target image\n",
    "contours, hierarchy = cv2.findContours(thresh2, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for c in contours:\n",
    "    # Iterate through each contour in the target image and \n",
    "    # use cv2.matchShapes to compare contour shapes\n",
    "    match = cv2.matchShapes(template_contour, c, 3, 0.0)\n",
    "    print (match)\n",
    "    # If the match value is less than 0.15 we\n",
    "    if match < 0.15:\n",
    "        closest_contour = c\n",
    "    else:\n",
    "        closest_contour = [] \n",
    "                \n",
    "cv2.drawContours(target, [closest_contour], -1, (0,255,0), 3)\n",
    "cv2.imshow('Output', target)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://docs.opencv.org/2.4/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Mini Project 2 - Identifiy Contours by Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load and then gray scale image\n",
    "\n",
    "image = cv2.imread('C:\\\\Users\\\\Sabakat\\\\Desktop\\\\images\\\\someshapes.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('Identifying Shapes',image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "ret, thresh = cv2.threshold(gray, 127, 255, 1)\n",
    "\n",
    "# Extract Contours\n",
    "contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "for cnt in contours:\n",
    "    \n",
    "    # Get approximate polygons\n",
    "    approx = cv2.approxPolyDP(cnt, 0.01*cv2.arcLength(cnt,True),True)\n",
    "    \n",
    "    if len(approx) == 3:\n",
    "        shape_name = \"Triangle\"\n",
    "        cv2.drawContours(image,[cnt],0,(0,255,0),-1)\n",
    "        \n",
    "        # Find contour center to place text at the center\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "        cv2.putText(image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "    \n",
    "    elif len(approx) == 4:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "        \n",
    "        # Check to see if 4-side polygon is square or rectangle\n",
    "        # cv2.boundingRect returns the top left and then width and \n",
    "        if abs(w-h) <= 3:\n",
    "            shape_name = \"Square\"\n",
    "            \n",
    "            # Find contour center to place text at the center\n",
    "            cv2.drawContours(image, [cnt], 0, (0, 125 ,255), -1)\n",
    "            cv2.putText(image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "        else:\n",
    "            shape_name = \"Rectangle\"\n",
    "            \n",
    "            # Find contour center to place text at the center\n",
    "            cv2.drawContours(image, [cnt], 0, (0, 0, 255), -1)\n",
    "            M = cv2.moments(cnt)\n",
    "            cx = int(M['m10'] / M['m00'])\n",
    "            cy = int(M['m01'] / M['m00'])\n",
    "            cv2.putText(image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "            \n",
    "    elif len(approx) == 10:\n",
    "        shape_name = \"Star\"\n",
    "        cv2.drawContours(image, [cnt], 0, (255, 255, 0), -1)\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "        cv2.putText(image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    elif len(approx) >= 15:\n",
    "        shape_name = \"Circle\"\n",
    "        cv2.drawContours(image, [cnt], 0, (0, 255, 255), -1)\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "        cv2.putText(image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "\n",
    "    cv2.imshow('Identifying Shapes',image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## Line Detection - Using Hough Lines\n",
    "   \n",
    "**cv2.HoughLines**(binarized/thresholded image, ùúå accuracy, ùúÉ accuracy, threshold)\n",
    "- Threshold here is the minimum vote for it to be considered a line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('C:\\\\Users\\\\Sabakat\\\\Desktop\\\\images\\\\soduku.jpg')\n",
    "\n",
    "# Grayscale and Canny Edges extracted\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 100, 170, apertureSize = 3)\n",
    "\n",
    "# Run HoughLines using a rho accuracy of 1 pixel\n",
    "# theta accuracy of np.pi / 180 which is 1 degree\n",
    "# Our line threshold is set to 240 (number of points on line)\n",
    "lines = cv2.HoughLines(edges, 1, np.pi / 180, 240)\n",
    "\n",
    "# We iterate through each line and convert it to the format\n",
    "# required by cv.lines (i.e. requiring end points)\n",
    "for rho, theta in lines[0]:\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a * rho\n",
    "    y0 = b * rho\n",
    "    x1 = int(x0 + 1000 * (-b))\n",
    "    y1 = int(y0 + 1000 * (a))\n",
    "    x2 = int(x0 - 1000 * (-b))\n",
    "    y2 = int(y0 - 1000 * (a))\n",
    "    cv2.line(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "cv2.imshow('Hough Lines', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic Hough Lines\n",
    "\n",
    "**cv2.HoughLinesP(binarized image, ùúå accuracy, ùúÉ accuracy, threshold, minimum line length, max line gap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Grayscale and Canny Edges extracted\n",
    "image = cv2.imread('C:\\\\Users\\\\Sabakat\\\\Desktop\\\\images\\\\soduku.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 100, 170, apertureSize = 3)\n",
    "\n",
    "# Again we use the same rho and theta accuracies\n",
    "# However, we specific a minimum vote (pts along line) of 100\n",
    "# and Min line length of 5 pixels and max gap between lines of 10 pixels\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 200, 5, 10)\n",
    "print (lines.shape)\n",
    "\n",
    "for x1, y1, x2, y2 in lines[0]:\n",
    "    cv2.line(image, (x1, y1), (x2, y2),(0, 255, 0), 3)\n",
    "\n",
    "cv2.imshow('Probabilistic Hough Lines', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://cmp.felk.cvut.cz/~matas/papers/matas-bmvc98.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Circle Detection - Hough Cirlces\n",
    "\n",
    "**cv2.HoughCircles**(image, method, dp, MinDist, param1, param2, minRadius, MaxRadius)\n",
    "\n",
    "\n",
    "- Method - currently only cv2.HOUGH_GRADIENT available\n",
    "- dp - Inverse ratio of accumulator resolution\n",
    "- MinDist - the minimum distance between the center of detected circles\n",
    "- param1 - Gradient value used in the edge detection\n",
    "- param2 - Accumulator threshold for the HOUGH_GRADIENT method (lower allows more circles to be detected (false positives))\n",
    "- minRadius - limits the smallest circle to this size (via radius)\n",
    "- MaxRadius - similarly sets the limit for the largest circles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'CV_HOUGH_GRADIENT'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-288abb2e405c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mcircles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHoughCircles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblur\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHOUGH_GRADIENT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#CV_HOUGH_GRADIENT HOUGH_GRADIENT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mcircles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHoughCircles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCV_HOUGH_GRADIENT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mcircles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcircles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'CV_HOUGH_GRADIENT'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "image = cv.imread('C:\\\\Users\\\\Sabakat\\\\Desktop\\\\images\\\\bottlecaps.jpg')\n",
    "gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY) #COLOR_BGR2HSV\n",
    "\n",
    "blur = cv.medianBlur(gray, 5)\n",
    "\n",
    "circles = cv.HoughCircles(blur, cv.HOUGH_GRADIENT, 1.5, 10)#CV_HOUGH_GRADIENT HOUGH_GRADIENT\n",
    "circles = cv.HoughCircles(gray, cv.CV_HOUGH_GRADIENT, 1, 10)\n",
    "\n",
    "circles = np.uint16(np.around(circles))\n",
    "\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv.circle(image,(i[0], i[1]), i[2], (255, 0, 0), 2)\n",
    "    \n",
    "    # draw the center of the circle\n",
    "    cv.circle(image, (i[0], i[1]), 2, (0, 255, 0), 5)\n",
    "\n",
    "cv.imshow('detected circles', image)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.1) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\hough.cpp:1728: error: (-215:Assertion failed) !_image.empty() && _image.type() == CV_8UC1 && (_image.isMat() || _image.isUMat()) in function 'cv::HoughCircles'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-82ae84bba0e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mblur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedianBlur\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mcircles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHoughCircles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblur\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHOUGH_GRADIENT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#CV_HOUGH_GRADIENT HOUGH_GRADIENT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mcircles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHoughCircles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCV_HOUGH_GRADIENT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.1.1) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\hough.cpp:1728: error: (-215:Assertion failed) !_image.empty() && _image.type() == CV_8UC1 && (_image.isMat() || _image.isUMat()) in function 'cv::HoughCircles'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "image = cv2.imread('C:\\\\Users\\\\Sabakat\\\\Desktop\\\\images\\\\bottlecaps.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2HSV) #COLOR_BGR2GRAY\n",
    "\n",
    "blur = cv2.medianBlur(gray, 5)\n",
    "\n",
    "circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1.5, 10)#CV_HOUGH_GRADIENT HOUGH_GRADIENT\n",
    "circles = cv2.HoughCircles(gray, cv.CV_HOUGH_GRADIENT, 1, 10)\n",
    "\n",
    "circles = np.uint16(np.around(circles))\n",
    "\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv2.circle(image,(i[0], i[1]), i[2], (255, 0, 0), 2)\n",
    "    \n",
    "    # draw the center of the circle\n",
    "    cv2.circle(image, (i[0], i[1]), 2, (0, 255, 0), 5)\n",
    "\n",
    "cv2.imshow('detected circles', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blob Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import cv2\n",
    "import numpy as np;\n",
    " \n",
    "# Read image\n",
    "image = cv2.imread(\"C:\\\\Users\\\\Sabakat\\\\Desktop\\\\images\\\\Sunflowers.jpg\")\n",
    " \n",
    "# Set up the detector with default parameters.\n",
    "detector = cv2.SimpleBlobDetector()\n",
    " \n",
    "# Detect blobs.\n",
    "keypoints = detector.detect(image)\n",
    " \n",
    "# Draw detected blobs as red circles.\n",
    "# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of\n",
    "# the circle corresponds to the size of blob\n",
    "blank = np.zeros((1,1)) \n",
    "blobs = cv2.drawKeypoints(image, keypoints, blank, (0,255,255),\n",
    "                                      cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
    " \n",
    "# Show keypoints\n",
    "cv2.imshow(\"Blobs\", blobs)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
